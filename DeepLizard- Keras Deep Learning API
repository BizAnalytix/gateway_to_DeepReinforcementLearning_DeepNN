3. Random- randint
sklearn.preprocessing- MinMaxScaler(feature_range=(0,1))
                        scaler.fit_transform((train_samples).reshape(-1,1))
                        
4. keras.models- Sequential([Dense(16, input_shape=(1,0), activation= 'relu'),
                              Dense(32, activation='relu'),
                              Dense(2, activation= 'softmax')])
                              
                  model.summary()
                  
5.  model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=2)


9.  model.save('medical_trial_model.h5')
    load_model
    get_weights
    optimiser
    
   json_string= Model.tojson()- saves only architecture
   Model.save_weights()
   Model.load_weights()
   model_from_json- reconstructing model from json string
   model.predict_classes(scaled_test_samples, batch_size=10, verbose=0
   plot_confusion_matrix 
   
  ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['dog', 'cat'], batch_size=10) 
    Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(224,224,3), use_bias=True, bias_initializer='zeros',padding='same'), #3 is channel in RGB layer
        MaxPooling2D(pool_size=(2,2), strides=2)
        Flatten(), #flattening to 1D tensor
        Dense(2, activation='softmax'),
   .compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])
   .fit_generator(train_batches, steps_per_epoch=4, 
                    validation_data=valid_batches, validation_steps=4, epochs=5, verbose=2)
   predict- model.predict_generator(test_batches, steps=1, verbose=0)
   
   
   keras.applications.vgg16.VGG16()
   model = Sequential()
for layer in vgg16_model.layers:
    model.add(layer)
    model.layers.pop()
     layer.trainable = False
     model.add(Dense(2, activation='softmax'))
13. Fine Tuning

DATA AUGMENTAION
ImageDataGenerator(rotation_range=10, width_shift_range=0.1, 
       height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, 
       channel_shift_range=10., horizontal_flip=True)
       
     image = np.expand_dims(ndimage.imread(image_path),0)
     
     gen.flow(image)
       
       os.environ['PYTHONHASSEED']='0'
       rn.seed(1234)
       from keras import backend as K
       tf.set_random_seed(89)
       K.set_session(sess)
       
31. MobileNet is of 31 mb and 4.2 mn parameters while VGG16 is of 553 mb and 138 mn parameters
   Keras.preprocessing - Image- Load_img, imag_to array
   np= expand_dims(axis=0)
   keras.applications- mobilenet.preprocess_input
                       Imagenet_utils.decode_predictions
                    
32. ImageDataGenerator- flow_from_directory
    
    keras.layers.core- Dense constructor, fn- trainable
    
    keras.model- Models constructor
                
                 model.fit_generator
                 model.predict_generator  
                 
    sklearn.metrics - confusion_matrix
                      plotconfusion_matrix
    
    
    FLASK
    from flask import request
from flask import jsonify
from flask import Flask

app = Flask(__name__) #creating an instance of flask class #name of application #__ bcz we are using a single module
#export FLASH_APP= hello_app.py
#flask run --host=0.0.0.0

@app.route('/hello',methods=['POST']) #method- what kind of http request is allowed
def hello():
    message = request.get_json(force=True) #always parse json even if it is unsure of data type
    name = message['name']
    response = {
        'greeting': 'Hello, ' + name + '!'
    }
    return jsonify(response) #convert python dictionary into json
    
    Image.open(io.BytesIO(decoded))
    
    To show the values from data to visual- 
    head- d3-data visualization api,crossfileter- ways to interact with and explore dataset in browser(cf.dimensions),  dc- rowchart, piechart 

Instead of data flowing towards model, we can have model transferred towards data for privacy of data
